# LLM Customer Support Example

This small worked example uses OpenAI to analyze message threads for customers, and for each,
provide a structured response that allows categorization of the latest request.

It could be extended with streaming/real-time responses; retrieval of relevant documents to
enhance the context offered to the LLM, and parallel queries with different context and different
structured outputs to drive multiple action and fact APIs which are then summarized into a final result.

